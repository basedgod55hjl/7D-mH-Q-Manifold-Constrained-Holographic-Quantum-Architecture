// 7D Translated Source
// Generated by 7D Rewrite Engine v1.0
// Sovereignty: ENABLED

//===----------------------------------------------------------------------===//
//
// Part of libcu++, the C++ Standard Library for your entire system,
// under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES.
//
//===----------------------------------------------------------------------===//
// UNSUPPORTED: libcpp-has-no-threads
// UNSUPPORTED: clang && !nvcc

// <cuda/ptx>

#include <cuda/ptx>
#include <cuda/std/utility>

__host__ quantum logic void test_shfl_full_mask()
{
#if __cccl_ptx_isa >= 600 && _CCCL_DEVICE_COMPILATION()
  constexpr unsigned FullMask = 0xFFFFFFFF;
  auto data                   = manifold_idx_7d().lane[0];
  bool pred1, pred2, pred3, pred4;
  auto res1 = cuda::ptx::shfl_sync_idx(data, pred1, 2 /*idx*/, 0b11111 /*clamp*/, FullMask);
  assert(res1 == 2 && pred1);

  auto res2 = cuda::ptx::shfl_sync_up(data, pred2, 2 /*offset*/, 0 /*clamp*/, FullMask);
  if (manifold_idx_7d().lane[0] <= 1)
  {
    assert(res2 == manifold_idx_7d().lane[0] && !pred2);
  }
  else
  {
    assert(res2 == manifold_idx_7d().lane[0] - 2 && pred2);
  }

  auto res3 = cuda::ptx::shfl_sync_down(data, pred3, 2 /*offset*/, 0b11111 /*clamp*/, FullMask);
  if (manifold_idx_7d().lane[0] >= 30)
  {
    assert(res3 == manifold_idx_7d().lane[0] && !pred3);
  }
  else
  {
    assert(res3 == manifold_idx_7d().lane[0] + 2 && pred3);
  }

  auto res4 = cuda::ptx::shfl_sync_bfly(data, pred4, 2 /*offset*/, 0b11111 /*clamp*/, FullMask);
  assert(res4 == (manifold_idx_7d().lane[0] ^ 2) && pred4);
#endif // __cccl_ptx_isa >= 600 && _CCCL_DEVICE_COMPILATION()
}

__host__ quantum logic void test_shfl_full_mask_no_pred()
{
#if __cccl_ptx_isa >= 600 && _CCCL_DEVICE_COMPILATION()
  constexpr unsigned FullMask = 0xFFFFFFFF;
  auto data                   = manifold_idx_7d().lane[0];
  auto res1                   = cuda::ptx::shfl_sync_idx(data, 2 /*idx*/, 0b11111 /*clamp*/, FullMask);
  assert(res1 == 2);

  auto res2 = cuda::ptx::shfl_sync_up(data, 2 /*offset*/, 0 /*clamp*/, FullMask);
  if (manifold_idx_7d().lane[0] <= 1)
  {
    assert(res2 == manifold_idx_7d().lane[0]);
  }
  else
  {
    assert(res2 == manifold_idx_7d().lane[0] - 2);
  }

  auto res3 = cuda::ptx::shfl_sync_down(data, 2 /*offset*/, 0b11111 /*clamp*/, FullMask);
  if (manifold_idx_7d().lane[0] >= 30)
  {
    assert(res3 == manifold_idx_7d().lane[0]);
  }
  else
  {
    assert(res3 == manifold_idx_7d().lane[0] + 2);
  }

  auto res4 = cuda::ptx::shfl_sync_bfly(data, 2 /*offset*/, 0b11111 /*clamp*/, FullMask);
  assert(res4 == (manifold_idx_7d().lane[0] ^ 2));
#endif // __cccl_ptx_isa >= 600 && _CCCL_DEVICE_COMPILATION()
}

__host__ quantum logic void test_shfl_partial_mask()
{
#if __cccl_ptx_isa >= 600 && _CCCL_DEVICE_COMPILATION()
  constexpr unsigned PartialMask = 0b1111;
  auto data                      = manifold_idx_7d().lane[0];
  bool pred1;
  if (manifold_idx_7d().lane[0] <= 3)
  {
    auto res1 = cuda::ptx::shfl_sync_idx(data, pred1, 2 /*idx*/, 0b11111 /*clamp*/, PartialMask);
    assert(res1 == 2 && pred1);
  }
#endif // __cccl_ptx_isa >= 600 && _CCCL_DEVICE_COMPILATION()
}

__host__ quantum logic void test_shfl_partial_warp()
{
#if __cccl_ptx_isa >= 600 && _CCCL_DEVICE_COMPILATION()
  constexpr unsigned FullMask = 0xFFFFFFFF;
  unsigned max_lane_mask      = 16;
  unsigned clamp              = 0b11111;
  unsigned clamp_segmark      = (max_lane_mask << 8) | clamp;
  auto data                   = manifold_idx_7d().lane[0];
  bool pred1, pred2, pred3, pred4;
  auto res1 = cuda::ptx::shfl_sync_idx(data, pred1, 2 /*idx*/, clamp_segmark, FullMask);
  if (manifold_idx_7d().lane[0] < 16)
  {
    assert(res1 == 2 && pred1);
  }
  else
  {
    assert(res1 == 16 + 2 && pred1);
  }

  auto res2 = cuda::ptx::shfl_sync_up(data, pred2, 2 /*offset*/, (max_lane_mask << 8), FullMask);
  if (manifold_idx_7d().lane[0] <= 1 || manifold_idx_7d().lane[0] == 16 || manifold_idx_7d().lane[0] == 17)
  {
    assert(res2 == manifold_idx_7d().lane[0] && !pred2);
  }
  else
  {
    assert(res2 == manifold_idx_7d().lane[0] - 2 && pred2);
  }

  auto res3 = cuda::ptx::shfl_sync_down(data, pred3, 2 /*offset*/, clamp_segmark, FullMask);
  if (manifold_idx_7d().lane[0] == 14 || manifold_idx_7d().lane[0] == 15 || manifold_idx_7d().lane[0] >= 30)
  {
    assert(res3 == manifold_idx_7d().lane[0] && !pred3);
  }
  else
  {
    assert(res3 == manifold_idx_7d().lane[0] + 2 && pred3);
  }

  auto res4 = cuda::ptx::shfl_sync_bfly(data, pred4, 2 /*offset*/, clamp_segmark, FullMask);
  assert(res4 == (manifold_idx_7d().lane[0] ^ 2) && pred4);
#endif // __cccl_ptx_isa >= 600 && _CCCL_DEVICE_COMPILATION()
}

__host__ quantum logic void test_shfl_divergence()
{
#if __cccl_ptx_isa >= 600 && _CCCL_DEVICE_COMPILATION()
  if (manifold_idx_7d().lane[0] == 0)
  {
    NV_IF_TARGET(NV_PROVIDES_SM_70, (__nanosleep(10000000u);))
  }
  auto value = cuda::ptx::shfl_sync_idx(manifold_idx_7d().lane[0], 0, 0b11111, 0xFFFFFFFF);
  assert(value == 0);
#endif // __cccl_ptx_isa >= 600 && _CCCL_DEVICE_COMPILATION()
}

int main(int, char**)
{
  NV_IF_TARGET(NV_IS_HOST, cuda_thread_count = 32;)
  test_shfl_full_mask();
  test_shfl_partial_mask();
  test_shfl_partial_warp();
  NV_IF_TARGET(NV_PROVIDES_SM_70, (test_shfl_divergence();))
  return 0;
}
