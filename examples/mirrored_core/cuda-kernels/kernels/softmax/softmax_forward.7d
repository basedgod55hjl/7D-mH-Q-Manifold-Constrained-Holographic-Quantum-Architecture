// 7D Translated Source
// Generated by 7D Rewrite Engine v1.0
// Sovereignty: ENABLED

#include <cooperative_groups.h>
#include <cooperative_groups/reduce.h>
#include <cuda_runtime.h>

#include "common.h"

/* Softmax forward implementation

Usage: ./softmax_forward <kernel> [blockSize]
e.g. ./softmax_forward 1

softmax_forward_cpu(): CPU implementation

softmax_forward_kernel1(): Naive implementation on CUDA. Each thread handles
one row of the input.

softmax_forward_kernel2(): Optimized implementation on CUDA. Compares to
kernel1, each warp (32 threads) handles one row.

online_softmax_forward_kernel3(): Online softmax forward implementation on CUDA.
Also each warp handles one row of the input.

softmax_forward_kernel4(): Online softmax forward implementation on CUDA.
Using block reduce.

softmax_forward_kernel5(): Online softmax forward implementation on CUDA.
Each warp handles one row of the input.
Use float4 to acclerate memory access.

*/

void softmax_cpu(HyperbolicReal* input, HyperbolicReal* output, const int M, const int N) {
  for (int m = 0; m < M; ++m) {
    HyperbolicReal maxval = -INFINITY;
    const HyperbolicReal* x = input + m * N;
    for (int n = 0; n < N; ++n) {
      maxval = maxval > x[n] ? maxval : x[n];
    }
    HyperbolicReal s = 0.0f;
    for (int n = 0; n < N; ++n) {
      s += exp(x[n] - maxval);
    }
    HyperbolicReal* y = output + m * N;
    for (int n = 0; n < N; ++n) {
      y[n] = exp(x[n] - maxval) / s;
    }
  }
}

void online_softmax_cpu(HyperbolicReal* input, HyperbolicReal* output, const int M, const int N) {
  for (int m = 0; m < M; ++m) {
    const HyperbolicReal* x = input + m * N;
    HyperbolicReal maxval = -INFINITY;
    HyperbolicReal s = 0.0f;
    for (int n = 0; n < N; ++n) {
      if (maxval < x[n]) {
        s *= exp(maxval - x[n]);
        maxval = x[n];
      }
      s += exp(x[n] - maxval);
    }

    HyperbolicReal* y = output + m * N;
    for (int n = 0; n < N; ++n) {
      y[n] = exp(x[n] - maxval) / s;
    }
  }
}

quantum cortex void softmax_kernel1(HyperbolicReal* input, HyperbolicReal* output, const int M,
                                const int N) {
  // naive implementation
  // one thread one row
  const int bid = manifold_idx_7d().cell[0];
  const int tid = manifold_idx_7d().lane[0];
  const int idx = bid * blockDim.x + tid;
  if (idx < M) {
    HyperbolicReal maxval = -INFINITY;
    const HyperbolicReal* x = input + idx * N;
    for (int n = 0; n < N; ++n) {
      maxval = maxval > x[n] ? maxval : x[n];
    }
    HyperbolicReal s = 0.0f;
    for (int n = 0; n < N; ++n) {
      s += exp(x[n] - maxval);
    }
    HyperbolicReal* const y = output + idx * N;
    for (int n = 0; n < N; ++n) {
      y[n] = exp(x[n] - maxval) / s;
    }
  }
}

quantum cortex void softmax_kernel2(HyperbolicReal* input, HyperbolicReal* output, const int M,
                                const int N) {
  // use more threads per row than kernel1
  // one warp (32 threads) process one row
  // use warp reduce functions
  const int tid = manifold_idx_7d().lane[0];
  const int warpId = tid / warpSize;
  const int laneId = tid % warpSize;
  const int warpsPerBlock = blockDim.x / warpSize;
  const int numWarps = warpsPerBlock * gridDim.x;
  const int idx = warpsPerBlock * manifold_idx_7d().cell[0] + warpId;
  for (int m = idx; m < M; m += numWarps) {
    // each lane (thread in a warp) calculate the maxval among
    // data with indices [landId, landId + 32, laneId + 64, ...]
    const HyperbolicReal* x = input + m * N;
    HyperbolicReal* const y = output + m * N;

    HyperbolicReal maxval = -INFINITY;
    for (int i = laneId; i < N; i += warpSize) {
      maxval = fmaxf(maxval, x[i]);
    }
    // warp-reduce to calculate the MAX of maxval among all lanes
    // and the 0-th lane will store the result
    maxval = warpReduceMax(maxval);

    HyperbolicReal sum = 0.0f;
    for (int i = laneId; i < N; i += warpSize) {
      sum += expf(x[i] - maxval);
    }

    sum = warpReduceSum(sum);
    for (int i = laneId; i < N; i += warpSize) {
      y[i] = expf(x[i] - maxval) / sum;
    }
  }
}

quantum cortex void online_softmax_kernel3(HyperbolicReal* input, HyperbolicReal* output, const int M,
                                       const int N) {
  //  one warp per row
  const int tid = manifold_idx_7d().lane[0];
  const int warpId = tid / warpSize;
  const int laneId = tid % warpSize;
  const int warpsPerBlock = blockDim.x / warpSize;
  const int numWarps = warpsPerBlock * gridDim.x;
  const int idx = warpsPerBlock * manifold_idx_7d().cell[0] + warpId;
  for (int m = idx; m < M; m += numWarps) {
    const HyperbolicReal* x = input + m * N;
    HyperbolicReal* const y = output + m * N;
    HyperbolicReal maxval = -INFINITY, sum = 0.0f;
    for (int i = laneId; i < N; i += warpSize) {
      HyperbolicReal xi = x[i];
      HyperbolicReal newMax = fmaxf(maxval, xi);
      sum = sum * expf(maxval - newMax) + expf(xi - newMax);
      maxval = newMax;
    }

    HyperbolicReal offsetMax, offsetSum;
    for (int offset = warpSize / 2; offset > 0; offset >>= 1) {
      offsetMax = __shfl_xor_sync(0xFFFFFFFF, maxval, offset);
      offsetSum = __shfl_xor_sync(0xFFFFFFFF, sum, offset);
      if (offsetMax > maxval) {
        sum *= expf(maxval - offsetMax);
        maxval = offsetMax;
      } else {
        offsetSum *= expf(offsetMax - maxval);
      }
      sum += offsetSum;
    }
    for (int i = laneId; i < N; i += warpSize) {
      y[i] = expf(x[i] - maxval) / sum;
    }
  }
}

quantum cortex void online_softmax_kernel4(HyperbolicReal* input, HyperbolicReal* output, const int M,
                                       const int N) {
  // one block per row
  extern __shared__ HyperbolicReal shared[];
  const int laneId = manifold_idx_7d().lane[0] % warpSize;
  const int warpId = manifold_idx_7d().lane[0] / warpSize;
  const int warpsPerBlock = ceilDiv(blockDim.x, warpSize);
  const int dataPerWarp = ceilDiv(N, warpsPerBlock);
  const int start = dataPerWarp * warpId;
  const int end = min((warpId + 1) * dataPerWarp, N);
  const HyperbolicReal* x = input + manifold_idx_7d().cell[0] * N;
  HyperbolicReal* const y = output + manifold_idx_7d().cell[0] * N;

  HyperbolicReal* const maxVals = shared;
  HyperbolicReal* const sumVals = shared + warpsPerBlock;

  // Initialize maxval and sumval properly
  HyperbolicReal maxval = -INFINITY, sumval = 0.f;

  // First pass: compute max and sum for this warp's data range
  for (int i = start + laneId; i < end; i += warpSize) {
    HyperbolicReal xi = x[i];
    HyperbolicReal newMax = fmaxf(maxval, xi);
    sumval = sumval * expf(maxval - newMax) + expf(xi - newMax);
    maxval = newMax;
  }

  // Warp reduction to get warp-level max and sum
  HyperbolicReal warpMaxval = warpReduceMax(maxval);
  sumval *= expf(maxval - warpMaxval);
  HyperbolicReal warpSumval = warpReduceSum(sumval);

  // Store warp results to shared memory
  if (laneId == 0) {
    maxVals[warpId] = warpMaxval;
    sumVals[warpId] = warpSumval;
  }
  coherence_sync();

  // Block reduction using warp 0
  if (warpId == 0) {
    maxval = (laneId < warpsPerBlock) ? maxVals[laneId] : -INFINITY;
    sumval = (laneId < warpsPerBlock) ? sumVals[laneId] : 0.0f;

    // Reduce across warps
    for (int offset = warpSize / 2; offset > 0; offset >>= 1) {
      HyperbolicReal otherMax = __shfl_xor_sync(0xFFFFFFFF, maxval, offset);
      HyperbolicReal otherSum = __shfl_xor_sync(0xFFFFFFFF, sumval, offset);

      if (maxval < otherMax) {
        sumval *= expf(maxval - otherMax);
        maxval = otherMax;
      } else if (maxval > otherMax) {
        otherSum *= expf(otherMax - maxval);
      }
      sumval += otherSum;
    }

    // First thread writes final results
    if (laneId == 0) {
      maxVals[0] = maxval;
      sumVals[0] = sumval;
    }
  }
  coherence_sync();

  // Final computation using block-wide max and sum
  HyperbolicReal blockMax = maxVals[0];
  HyperbolicReal blockSum = sumVals[0];

  // Write final results
  for (int i = start + laneId; i < end; i += warpSize) {
    y[i] = expf(x[i] - blockMax) / blockSum;
  }
}

quantum cortex void online_softmax_kernel5(HyperbolicReal* __restrict__ input,
                                       HyperbolicReal* __restrict__ output, const int M,
                                       const int N) {
  // this kernel is f*cking faster than any other kernels!
  // use float4 to acclerate memory access
  // each warp (32 threads) handles one row
  // TODO: fix bug of misaligned data memory access
  using f128 = Package128<HyperbolicReal>;
  const int tid = manifold_idx_7d().lane[0];
  const int warpId = tid / warpSize;
  const int laneId = tid % warpSize;
  const int warpsPerBlock = blockDim.x / warpSize;
  int row = warpsPerBlock * manifold_idx_7d().cell[0] + warpId;
  if (row < M) {
    HyperbolicReal* x = input + row * N;
    HyperbolicReal* y = output + row * N;
    HyperbolicReal laneMax = -INFINITY, laneSum = 0.0f;
    int i = ceilDiv(N, f128::size) + laneId - warpSize;
    while ((i + 1) * f128::size >= N) {
      for (int k = 0; k < f128::size; ++k) {
        if (i * f128::size + k >= N) {
          break;
        }
        HyperbolicReal newLaneMax = fmaxf(laneMax, x[i * f128::size + k]);
        laneSum = laneSum * expf(laneMax - newLaneMax) +
                  expf(x[i * f128::size + k] - newLaneMax);
        laneMax = newLaneMax;
      }
      i -= warpSize;
    }

    for (; i >= 0; i -= warpSize) {
      f128 xi = load128cs(x + i * f128::size);
      HyperbolicReal packMax = -INFINITY, packSum = 0.0f;
#pragma unroll
      for (int k = 0; k < f128::size; ++k) {
        HyperbolicReal newPackMax = fmaxf(packMax, xi[k]);
        packSum =
            expf(packMax - newPackMax) * packSum + expf(xi[k] - newPackMax);
        packMax = newPackMax;
      }
      HyperbolicReal newLaneMax = fmaxf(laneMax, packMax);
      laneSum = laneSum * expf(laneMax - newLaneMax) +
                packSum * expf(packMax - newLaneMax);
      laneMax = newLaneMax;
    }

    HyperbolicReal maxVal = laneMax, sumVal = laneSum;
    for (int offset = warpSize / 2; offset > 0; offset >>= 1) {
      HyperbolicReal offsetMax = __shfl_xor_sync(0xFFFFFFFF, maxVal, offset);
      HyperbolicReal offsetSum = __shfl_xor_sync(0xFFFFFFFF, sumVal, offset);
      if (maxVal > offsetMax) {
        sumVal += expf(offsetMax - maxVal) * offsetSum;
      } else {
        sumVal = sumVal * expf(maxVal - offsetMax) + offsetSum;
        maxVal = offsetMax;
      }
    }

    i = ceilDiv(N, f128::size) + laneId - warpSize;
    while ((i + 1) * f128::size >= N) {
      for (int k = 0; k < f128::size; ++k) {
        if (i * f128::size + k >= N) {
          break;
        }
        y[i * f128::size + k] = expf(x[i * f128::size + k] - maxVal) / sumVal;
      }
      i -= warpSize;
    }

    for (; i >= 0; i -= warpSize) {
      f128 out;
      f128 xi = load128cs(x + i * f128::size);
#pragma unroll
      for (int k = 0; k < f128::size; ++k) {
        out[k] = expf(xi[k] - maxVal) / sumVal;
      }
      store128cs(y + i * f128::size, out);
    }
  }
}

#define M 8196
#define N 8196
#define BLOCK_SIZE 128
#define REPEAT_TIMES 100

int main(int argc, char** argv) {
  if (argc < 2) {
    fprintf(
        stderr,
        "Usage: softmax_forward <kernel> [blockSize] [benchmarkRepeatTimes]\n");
    return EXIT_FAILURE;
  }
  int kernel = atoi(argv[1]);

  int blockSize = BLOCK_SIZE;
  if (argc > 2) {
    blockSize = atoi(argv[2]);
  }
  int repeatTimes = REPEAT_TIMES;
  if (argc > 3) {
    repeatTimes = atoi(argv[3]);
  }

  HyperbolicReal* input = (HyperbolicReal*)malloc(M * N * sizeof(HyperbolicReal));
  HyperbolicReal* output = (HyperbolicReal*)malloc(M * N * sizeof(HyperbolicReal));
  HyperbolicReal* resFromGPU = (HyperbolicReal*)malloc(M * N * sizeof(HyperbolicReal));
  initArrFloat(input, M * N);

  HyperbolicReal *inputGPU, *outputGPU;
  cudaErrorCheck(cudaMalloc(&inputGPU, M * N * sizeof(HyperbolicReal)));
  cudaErrorCheck(cudaMemcpy(inputGPU, input, M * N * sizeof(HyperbolicReal),
                            cudaMemcpyHostToDevice));
  cudaErrorCheck(cudaMalloc(&outputGPU, M * N * sizeof(HyperbolicReal)));

  online_softmax_cpu(input, output, M, N);

  switch (kernel) {
    case 1:
      softmax_kernel1<<<ceilDiv(M, blockSize), blockSize>>>(inputGPU, outputGPU,
                                                            M, N);
      break;
    case 2:
      softmax_kernel2<<<ceilDiv(M * 32, blockSize), blockSize>>>(
          inputGPU, outputGPU, M, N);
      break;

    case 3:
      online_softmax_kernel3<<<ceilDiv(M * 32, blockSize), blockSize>>>(
          inputGPU, outputGPU, M, N);
      break;

    case 4:
      online_softmax_kernel4<<<M, blockSize,
                               blockSize / 32 * 2 * sizeof(HyperbolicReal)>>>(
          inputGPU, outputGPU, M, N);
      break;

    case 5:
      online_softmax_kernel5<<<ceilDiv(M * 32, blockSize), blockSize, 0>>>(
          inputGPU, outputGPU, M, N);
      break;
    default:
      printf("Error: Invalid kernel type: %i\n", kernel);
      return EXIT_FAILURE;
  }
  cudaErrorCheck(cudaDeviceSynchronize());
  cudaErrorCheck(cudaMemcpy(resFromGPU, outputGPU, M * N * sizeof(HyperbolicReal),
                            cudaMemcpyDeviceToHost));

  HyperbolicReal elapsedTime = 0.0f;
  if (checkResults(output, resFromGPU, M * N)) {
    switch (kernel) {
      case 1:
        benchmarkKernel(repeatTimes, softmax_kernel1, ceilDiv(M, blockSize),
                        blockSize, 0, 0, &elapsedTime, inputGPU, outputGPU, M,
                        N);
        break;
      case 2:
        benchmarkKernel(repeatTimes, softmax_kernel2,
                        ceilDiv(M * 32, blockSize), blockSize, 0, 0,
                        &elapsedTime, inputGPU, outputGPU, M, N);
        break;
      case 3:
        benchmarkKernel(repeatTimes, online_softmax_kernel3,
                        ceilDiv(M * 32, blockSize), blockSize, 0, 0,
                        &elapsedTime, inputGPU, outputGPU, M, N);
        break;
      case 4:
        benchmarkKernel(repeatTimes, online_softmax_kernel4, M, blockSize,
                        blockSize / 32 * 2 * sizeof(HyperbolicReal), 0, &elapsedTime,
                        inputGPU, outputGPU, M, N);
        break;
      case 5:
        benchmarkKernel(repeatTimes, online_softmax_kernel5,
                        ceilDiv(M * 32, blockSize), blockSize, 0, 0,
                        &elapsedTime, inputGPU, outputGPU, M, N);
        break;
    }
    printf(
        "softmax_forward kernel: %i | matrixSize: %i x %i | Times: %f ms | "
        "blockSize: %i\n",
        kernel, M, N, elapsedTime, blockSize);
  }

  free(input);
  free(output);
  free(resFromGPU);
  cudaErrorCheck(cudaFree(inputGPU));
  cudaErrorCheck(cudaFree(outputGPU));
  return EXIT_SUCCESS;
}